{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f8eedaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrose_hiive as mlrose\n",
    "import numpy as np\n",
    "import math\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, LearningCurveDisplay, ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "np.random.seed(88)\n",
    "# switch off the chatter\n",
    "logging.basicConfig(level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d1afe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "RHC_COLOR = 'tab:blue'\n",
    "SA_COLOR = 'tab:orange'\n",
    "GA_COLOR = 'tab:green'\n",
    "MIMIC_COLOR = 'tab:red'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a81592",
   "metadata": {},
   "source": [
    "## Discrete Optimization Problem  Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a6f3970",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Randomized Hill Climbing Algorithm\n",
    "https://mlrose.readthedocs.io/en/stable/source/algorithms.html#mlrose.algorithms.random_hill_climb\n",
    "Params: max_attempts=50, restarts=10\n",
    "'''\n",
    "def rhc(problem, restarts=10):\n",
    "    t0 = time.time()\n",
    "    _, best_fitness, curve = mlrose.random_hill_climb(problem=problem, max_attempts=50, restarts=restarts, curve=True)\n",
    "    t1 = time.time()\n",
    "    return best_fitness, t1-t0, curve\n",
    "\n",
    "'''\n",
    "Simulated Annealing Algorithm\n",
    "https://mlrose.readthedocs.io/en/stable/source/algorithms.html#mlrose.algorithms.simulated_annealing\n",
    "Params: max_attempts=50\n",
    "'''\n",
    "def sa(problem, schedule=mlrose.GeomDecay()):\n",
    "    t0 = time.time()\n",
    "    _, best_fitness, curve = mlrose.simulated_annealing(problem=problem, curve=True, max_attempts=25,\n",
    "                                                        schedule=schedule)\n",
    "    t1 = time.time()\n",
    "    return best_fitness, t1-t0, curve\n",
    "\n",
    "'''\n",
    "Genetic Algorithm\n",
    "https://mlrose.readthedocs.io/en/stable/source/algorithms.html#mlrose.algorithms.genetic_alg\n",
    "Params: max_attempts=50\n",
    "'''\n",
    "\n",
    "def ga(problem):\n",
    "    t0 = time.time()\n",
    "    _, best_fitness, curve = mlrose.genetic_alg(problem=problem, max_attempts=50, curve=True)\n",
    "    t1 = time.time()\n",
    "    return best_fitness, t1-t0, curve\n",
    "\n",
    "'''\n",
    "MIMIC Algorithm\n",
    "https://mlrose.readthedocs.io/en/stable/source/algorithms.html#mlrose.algorithms.mimic\n",
    "Params: max_attempts=50\n",
    "'''\n",
    "def mimic(problem):\n",
    "    t0 = time.time()\n",
    "    _, best_fitness, curve = mlrose.mimic(problem=problem, max_attempts=50, curve=True)\n",
    "    t1 = time.time()\n",
    "    return best_fitness, t1-t0, curve\n",
    "\n",
    "'''\n",
    "Generates data for best fitness score vs. problem size, time vs. problem size\n",
    "    inputs : range of integers used to define problem size\n",
    "    algorithm : optimization algorithm to run - rhc, sa, ga, mimic\n",
    "    problem : optimization problem to solve - 'OneMax', 'FourPeaks, 'Kcolor'\n",
    "'''    \n",
    "def fitness_time_trial(inputs, algorithm, problem):\n",
    "    fitnesses = []\n",
    "    times = []\n",
    "    if problem == 'OneMax':\n",
    "        fitness = mlrose.OneMax()\n",
    "        for x in inputs:\n",
    "            opt_problem = mlrose.DiscreteOpt(length=x, fitness_fn=fitness, maximize=True)\n",
    "            opt_problem.set_mimic_fast_mode(True)\n",
    "            trial_fitness, trial_time, _ = algorithm(opt_problem)\n",
    "            fitnesses.append(trial_fitness / x)\n",
    "            times.append(trial_time)\n",
    "    elif problem == 'FlipFlop':\n",
    "        fitness = mlrose.FlipFlop()\n",
    "        for x in inputs:\n",
    "            opt_problem = mlrose.FlipFlopGenerator.generate(size=x, seed=8)\n",
    "            opt_problem.set_mimic_fast_mode(True)\n",
    "            trial_fitness, trial_time, _ = algorithm(opt_problem)\n",
    "            fitnesses.append(trial_fitness)\n",
    "            times.append(trial_time)\n",
    "    elif problem == 'FourPeaks':\n",
    "        fitness = mlrose.FourPeaks(t_pct=0.1)\n",
    "        for x in inputs:\n",
    "            opt_problem = mlrose.DiscreteOpt(length=x, fitness_fn=fitness, maximize=True)\n",
    "            opt_problem.set_mimic_fast_mode(True)\n",
    "            trial_fitness, trial_time, _ = algorithm(opt_problem)\n",
    "            fitnesses.append(trial_fitness)\n",
    "            times.append(trial_time)\n",
    "    return np.asarray(fitnesses), np.asarray(times)\n",
    "\n",
    "'''\n",
    "Generate and save plot of results for a problem\n",
    "'''\n",
    "# generate graphs\n",
    "def fitness_time_experiment(problem, fname, inputs, runs):\n",
    "    t0 = time.time()\n",
    "    # Problem sizes\n",
    "    fig, axs = plt.subplots(2, figsize=(12, 12))\n",
    "    algorithms = [rhc, sa, ga, mimic]\n",
    "    colors = [RHC_COLOR, SA_COLOR, GA_COLOR, MIMIC_COLOR]\n",
    "    labels = ['Random Hill Climbing', 'Simulated Annealing', 'Genetic Algorithm', 'MIMIC']\n",
    "    for i in range(len(colors)):\n",
    "        algo = algorithms[i]\n",
    "        color = colors[i]\n",
    "        fitness_arr = []\n",
    "        time_arr = []\n",
    "        for j in range(runs):\n",
    "            fit, t = fitness_time_trial(inputs, algo, problem)\n",
    "            fitness_arr.append(fit)\n",
    "            time_arr.append(t)\n",
    "        fitness = np.asarray(fitness_arr).mean(axis=0)\n",
    "        times = np.asarray(time_arr).mean(axis=0)\n",
    "        axs[0].plot(inputs, fitness, label=labels[i], color=color)\n",
    "        axs[1].plot(inputs, times, label=labels[i], color=color)\n",
    "    axs[0].set_xlabel('Problem Size')\n",
    "    axs[1].set_xlabel('Problem Size')\n",
    "    if problem == 'OneMax':\n",
    "        axs[0].set_ylabel('Best Fitness Score / Max Fitness Score')\n",
    "    else:\n",
    "        axs[0].set_ylabel('Best Fitness Score')\n",
    "    axs[1].set_ylabel('Time [Seconds]')\n",
    "    axs[0].legend(labels, loc='lower left')\n",
    "    axs[1].legend(labels, loc='upper left')\n",
    "    axs[0].set_title('Fitness Score vs. Problem Size')\n",
    "    axs[1].set_title('Time vs. Problem Size')\n",
    "    plt.savefig(fname=fname)\n",
    "    return time.time() - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2428750f",
   "metadata": {},
   "source": [
    "## Neural Network Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93e2b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "scaler = MinMaxScaler()\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "X = np.asarray(scaler.fit_transform(data.data))\n",
    "Y = np.asarray(one_hot.fit_transform(data.target.reshape(-1, 1)).todense())\n",
    "\n",
    "# Split data\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, random_state=8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45d94022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "backprop_NN = MLPClassifier(alpha=1e-4, max_iter=1000, hidden_layer_sizes=(50, 50), \n",
    "                         random_state=8, learning_rate='constant', early_stopping=True)\n",
    "\n",
    "rhc_NN = mlrose.NeuralNetwork(algorithm='random_hill_climb', max_iters=1000, early_stopping=True,\n",
    "                              restarts=10, random_state=8, curve=True, hidden_nodes=(50, 50))\n",
    "\n",
    "sa_NN = mlrose.NeuralNetwork(algorithm='simulated_annealing', max_iters=1000, early_stopping=True, random_state=8,\n",
    "                             curve=True, hidden_nodes=(50, 50))\n",
    "\n",
    "ga_NN = mlrose.NeuralNetwork(algorithm='genetic_alg', max_iters=1000, early_stopping=True, random_state=8,\n",
    "                             curve=True, hidden_nodes=(50, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51ef3cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_accuracy_plots():\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(18, 8), sharey=True)\n",
    "    common_params = {\n",
    "        \"X\": np.asarray(X),\n",
    "        \"y\": np.asarray(Y),\n",
    "        \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "        \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
    "        \"score_type\": \"both\",\n",
    "        \"n_jobs\": 4,\n",
    "        \"line_kw\": {\"marker\": \"o\"},\n",
    "        \"std_display_style\": \"fill_between\",\n",
    "        \"score_name\": \"Accuracy\",\n",
    "    }\n",
    "\n",
    "    titles = ['Backpropagation', 'Randomized Hill Climbing',\n",
    "              'Simulated Annealing', 'Genetic Algorithm']\n",
    "    for ax_idx, estimator in enumerate([backprop_NN, rhc_NN, sa_NN, ga_NN]):\n",
    "        LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax[ax_idx])\n",
    "        handles, label = ax[ax_idx].get_legend_handles_labels()\n",
    "        ax[ax_idx].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
    "        ax[ax_idx].set_title(f\"Learning Curve for {titles[ax_idx]}\")\n",
    "    plt.savefig('NN_Learning_Curves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8336e14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_loss_plots():\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(20, 8), sharey=False)\n",
    "    titles = ['Backpropagation', 'Randomized Hill Climbing',\n",
    "              'Simulated Annealing', 'Genetic Algorithm']\n",
    "    for ax_idx, estimator in enumerate([backprop_NN, rhc_NN, sa_NN, ga_NN]):\n",
    "        estimator.fit(train_x, train_y)\n",
    "        if titles[ax_idx] == 'Backpropagation':\n",
    "            ax[ax_idx].plot(estimator.loss_curve_)\n",
    "            ax[ax_idx].set_ylabel('Loss')\n",
    "            ax[ax_idx].set_title(f\"Loss Curve for {titles[ax_idx]}\")\n",
    "        else:\n",
    "            ax[ax_idx].plot(estimator.fitness_curve)\n",
    "            ax[ax_idx].set_ylabel('Fitness')\n",
    "            ax[ax_idx].set_title(f\"Fitness Curve for {titles[ax_idx]}\")\n",
    "        ax[ax_idx].set_xlabel('Iterations')\n",
    "    plt.savefig('NN_Loss_Curves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d63fc574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_tuning():\n",
    "    default_parameters = {\n",
    "    'seed': 8,\n",
    "    'max_attempts': 5000,\n",
    "    'iteration_list': 2 ** np.arange(13),\n",
    "    'n_jobs':1,\n",
    "    'cv':5,\n",
    "    }\n",
    "    \n",
    "    default_grid_search_parameters = {\n",
    "    'max_iters': [5000],\n",
    "    'learning_rate_init': [0.1, 0.2, 0.4, 0.8],\n",
    "    'hidden_layer_sizes': [(4), (10), (4, 4), (50, 50), (4, 4, 4)],\n",
    "    'activation': [mlrose.neural.activation.relu, mlrose.neural.activation.sigmoid, mlrose.neural.activation.tanh]\n",
    "    }\n",
    "    \n",
    "    skmlp_grid_search_parameters = {\n",
    "    **default_grid_search_parameters,\n",
    "    'max_iters': [5000],\n",
    "    'learning_rate_init': [0.0001],\n",
    "    \n",
    "    }\n",
    "    skmlp_default_parameters = {\n",
    "    **default_parameters,\n",
    "    'early_stopping':True,\n",
    "    'tol':1e-05,\n",
    "    'alpha':0.001,\n",
    "    'solver':'lbfgs',\n",
    "    }\n",
    "        \n",
    "    \n",
    "    mlp_runner = mlrose.runners.SKMLPRunner(x_train=train_x, y_train=train_y,\n",
    "                                           x_test = test_x, y_test=test_y,\n",
    "                                           experiment_name='MLP_Tune',\n",
    "                                            grid_search_parameters=default_grid_search_parameters,\n",
    "                                            override_ctrl_c_handler=False,\n",
    "                                            **skmlp_default_parameters)\n",
    "    run_stats_df, curves_df, cv_results_df, cx_sr = mlp_runner.run()\n",
    "    return run_stats_df, curves_df, cv_results_df, cx_sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d0246",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    fitness_time_experiment('OneMax', 'OneMaxResults', np.arange(1, 201), 10)\n",
    "    fitness_time_experiment('FlipFlop', 'FlipFlopResults', np.arange(2,201), 10)\n",
    "    fitness_time_experiment('FourPeaks', 'FourPeaksResults', np.arange(2, 201), 10)\n",
    "    #mlp_tuning()\n",
    "    #NN_accuracy_plots()\n",
    "    #NN_loss_plots()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
